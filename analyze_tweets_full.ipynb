{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024b5a50-de85-45d4-ba89-9f036207af97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fpdf2\n",
      "  Downloading fpdf2-2.8.3-py2.py3-none-any.whl.metadata (69 kB)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from fpdf2) (0.7.1)\n",
      "Requirement already satisfied: Pillow!=9.2.*,>=6.2.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from fpdf2) (10.4.0)\n",
      "Requirement already satisfied: fonttools>=4.34.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from fpdf2) (4.51.0)\n",
      "Downloading fpdf2-2.8.3-py2.py3-none-any.whl (245 kB)\n",
      "Installing collected packages: fpdf2\n",
      "Successfully installed fpdf2-2.8.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fpdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8830092a-1df0-4d69-a8a3-5af4b8b4cf3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'latin-1' codec can't encode character '\\u2026' in position 674: ordinal not in range(256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 104\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m    102\u001b[0m     pdf\u001b[38;5;241m.\u001b[39mmulti_cell(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m8\u001b[39m, txt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m][:\u001b[38;5;241m150\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m... (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_category\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 104\u001b[0m pdf\u001b[38;5;241m.\u001b[39moutput(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTweet_Analysis_Report.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸŽ‰ All exports completed:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- analyzed_tweets.csv / .xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\fpdf\\fpdf.py:1065\u001b[0m, in \u001b[0;36mFPDF.output\u001b[1;34m(self, name, dest)\u001b[0m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m#Finish document if necessary\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m-> 1065\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1066\u001b[0m dest\u001b[38;5;241m=\u001b[39mdest\u001b[38;5;241m.\u001b[39mupper()\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(dest\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\fpdf\\fpdf.py:246\u001b[0m, in \u001b[0;36mFPDF.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_endpage()\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m#close document\u001b[39;00m\n\u001b[1;32m--> 246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enddoc()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\fpdf\\fpdf.py:1636\u001b[0m, in \u001b[0;36mFPDF._enddoc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_enddoc\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1635\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_putheader()\n\u001b[1;32m-> 1636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_putpages()\n\u001b[0;32m   1637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_putresources()\n\u001b[0;32m   1638\u001b[0m     \u001b[38;5;66;03m#Info\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\fpdf\\fpdf.py:1170\u001b[0m, in \u001b[0;36mFPDF._putpages\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;66;03m#Page content\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompress:\n\u001b[0;32m   1169\u001b[0m     \u001b[38;5;66;03m# manage binary data as latin1 until PEP461 or similar is implemented\u001b[39;00m\n\u001b[1;32m-> 1170\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpages[n]\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m PY3K \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpages[n] \n\u001b[0;32m   1171\u001b[0m     p \u001b[38;5;241m=\u001b[39m zlib\u001b[38;5;241m.\u001b[39mcompress(p)\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'latin-1' codec can't encode character '\\u2026' in position 674: ordinal not in range(256)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from fpdf import FPDF\n",
    "import os\n",
    "\n",
    "# Load the tweets\n",
    "df = pd.read_csv(\"tweets_output.csv\")\n",
    "df['created_at'] = pd.to_datetime(df['created_at']).dt.tz_localize(None)\n",
    "\n",
    "# Sentiment analysis\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(str(text))\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "df['sentiment_score'] = df['text'].apply(get_sentiment)\n",
    "\n",
    "def categorize(score):\n",
    "    if score > 0.1:\n",
    "        return 'positive'\n",
    "    elif score < -0.1:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df['sentiment_category'] = df['sentiment_score'].apply(categorize)\n",
    "\n",
    "# Save analyzed data\n",
    "df.to_csv(\"analyzed_tweets.csv\", index=False)\n",
    "df.to_excel(\"analyzed_tweets.xlsx\", index=False)\n",
    "\n",
    "# Plot 1: Sentiment distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df, x='sentiment_category', hue='sentiment_category', palette='Set2', legend=False)\n",
    "plt.title(\"Tweet Sentiment Distribution\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig_sentiment_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "# Plot 2: Average sentiment over time\n",
    "df['date'] = pd.to_datetime(df['created_at']).dt.date\n",
    "daily_sentiment = df.groupby('date')['sentiment_score'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.lineplot(data=daily_sentiment, x='date', y='sentiment_score', marker='o')\n",
    "plt.title(\"Average Sentiment Score Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Sentiment\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig_sentiment_over_time.png\")\n",
    "plt.close()\n",
    "\n",
    "# Create Word report\n",
    "doc = Document()\n",
    "doc.add_heading('Polio Vaccine Tweet Analysis Report', 0)\n",
    "\n",
    "doc.add_heading('1. Overview', level=1)\n",
    "doc.add_paragraph('This report analyzes sentiment in tweets related to polio vaccines in Kenya.')\n",
    "\n",
    "doc.add_heading('2. Sentiment Distribution', level=1)\n",
    "doc.add_picture('fig_sentiment_distribution.png', width=Inches(5.5))\n",
    "doc.add_paragraph('This chart shows the distribution of positive, neutral, and negative tweets.')\n",
    "\n",
    "doc.add_heading('3. Sentiment Over Time', level=1)\n",
    "doc.add_picture('fig_sentiment_over_time.png', width=Inches(5.5))\n",
    "doc.add_paragraph('This line chart illustrates how average sentiment changes over time.')\n",
    "\n",
    "doc.add_heading('4. Sample Tweets', level=1)\n",
    "for i, row in df.head(5).iterrows():\n",
    "    doc.add_paragraph(f\"- {row['text'][:150]}... ({row['sentiment_category']})\")\n",
    "\n",
    "doc.save(\"Tweet_Analysis_Report.docx\")\n",
    "\n",
    "# Create PDF version using FPDF\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size=12)\n",
    "pdf.cell(200, 10, txt=\"Polio Vaccine Tweet Analysis Report\", ln=True, align='C')\n",
    "\n",
    "pdf.ln(10)\n",
    "pdf.set_font(\"Arial\", size=10)\n",
    "pdf.multi_cell(0, 10, txt=\"This report analyzes sentiment in tweets related to polio vaccines in Kenya.\")\n",
    "\n",
    "pdf.ln(10)\n",
    "pdf.cell(0, 10, \"Sentiment Distribution\", ln=True)\n",
    "pdf.image(\"fig_sentiment_distribution.png\", w=180)\n",
    "\n",
    "pdf.ln(10)\n",
    "pdf.cell(0, 10, \"Average Sentiment Over Time\", ln=True)\n",
    "pdf.image(\"fig_sentiment_over_time.png\", w=180)\n",
    "\n",
    "pdf.ln(10)\n",
    "pdf.cell(0, 10, \"Sample Tweets\", ln=True)\n",
    "for i, row in df.head(5).iterrows():\n",
    "    pdf.multi_cell(0, 8, txt=f\"- {row['text'][:150]}... ({row['sentiment_category']})\")\n",
    "\n",
    "pdf.output(\"Tweet_Analysis_Report.pdf\")\n",
    "\n",
    "print(\"ðŸŽ‰ All exports completed:\")\n",
    "print(\"- analyzed_tweets.csv / .xlsx\")\n",
    "print(\"- sentiment charts (.png)\")\n",
    "print(\"- Word: Tweet_Analysis_Report.docx\")\n",
    "print(\"- PDF: Tweet_Analysis_Report.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1b2b96-c8c4-45b6-842c-a321b6d34cc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1633507366.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install pandas matplotlib seaborn textblob openpyxl python-docx fpdf\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install pandas matplotlib seaborn textblob openpyxl python-docx fpdf\n",
    "python -m textblob.download_corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ff51cf-6ce4-4489-95a4-dff566c402d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\administrator\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\administrator\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\administrator\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: textblob in c:\\users\\administrator\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\administrator\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: python-docx in c:\\users\\administrator\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from python-docx) (4.11.0)\n",
      "Requirement already satisfied: click in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (4.66.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas matplotlib seaborn textblob openpyxl python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b593ab-b77e-42f2-afaf-5f1eec968406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd9d190a-25d9-48b6-b685-c4e7ebc2131c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tweets.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Load tweets\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweets.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Change this if your file is named differently\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Ensure datetime is timezone-naive if needed\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mand\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_datetime64_any_dtype(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tweets.csv'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from fpdf import FPDF\n",
    "import os\n",
    "\n",
    "# Load tweets\n",
    "df = pd.read_csv(\"tweets.csv\")  # Change this if your file is named differently\n",
    "\n",
    "# Ensure datetime is timezone-naive if needed\n",
    "if 'date' in df.columns and pd.api.types.is_datetime64_any_dtype(df['date']):\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.tz_localize(None)\n",
    "\n",
    "# Clean and analyze text\n",
    "def clean_text(text):\n",
    "    return str(text).strip().replace('\\n', ' ')\n",
    "\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    return polarity\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "df['sentiment_score'] = df['text'].apply(get_sentiment)\n",
    "df['sentiment_category'] = df['sentiment_score'].apply(lambda x: 'positive' if x > 0.1 else 'negative' if x < -0.1 else 'neutral')\n",
    "\n",
    "# Export as CSV and Excel\n",
    "df.to_csv(\"analyzed_tweets.csv\", index=False)\n",
    "df.to_excel(\"analyzed_tweets.xlsx\", index=False)\n",
    "\n",
    "# Sentiment distribution plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df, x='sentiment_category', palette='Set2')\n",
    "plt.title(\"Sentiment Distribution\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Tweet Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"sentiment_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "# Sentiment score histogram\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(df['sentiment_score'], bins=30, kde=True)\n",
    "plt.title(\"Sentiment Score Histogram\")\n",
    "plt.xlabel(\"Sentiment Score\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"sentiment_histogram.png\")\n",
    "plt.close()\n",
    "\n",
    "# Export Word report\n",
    "doc = Document()\n",
    "doc.add_heading(\"Tweet Sentiment Analysis Report\", 0)\n",
    "doc.add_paragraph(\"This report summarizes the sentiment analysis of tweets.\")\n",
    "\n",
    "# Summary stats\n",
    "doc.add_heading(\"Summary\", level=1)\n",
    "sentiment_counts = df['sentiment_category'].value_counts().to_dict()\n",
    "for k, v in sentiment_counts.items():\n",
    "    doc.add_paragraph(f\"{k.title()}: {v} tweets\")\n",
    "\n",
    "# Insert plots\n",
    "doc.add_heading(\"Visualizations\", level=1)\n",
    "doc.add_picture(\"sentiment_distribution.png\", width=Inches(5))\n",
    "doc.add_picture(\"sentiment_histogram.png\", width=Inches(5))\n",
    "\n",
    "# Add sample tweets\n",
    "doc.add_heading(\"Sample Tweets\", level=1)\n",
    "for i, row in df.head(5).iterrows():\n",
    "    doc.add_paragraph(f\"- {row['text'][:150]}... ({row['sentiment_category']})\")\n",
    "\n",
    "doc.save(\"Tweet_Analysis_Report.docx\")\n",
    "\n",
    "# Export PDF report\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size=12)\n",
    "pdf.multi_cell(0, 10, txt=\"Tweet Sentiment Analysis Report\", align='C')\n",
    "\n",
    "pdf.set_font(\"Arial\", size=10)\n",
    "pdf.ln(10)\n",
    "pdf.multi_cell(0, 8, txt=\"Summary:\\n\", align='L')\n",
    "for k, v in sentiment_counts.items():\n",
    "    pdf.multi_cell(0, 8, txt=f\"{k.title()}: {v} tweets\")\n",
    "\n",
    "pdf.ln(5)\n",
    "pdf.multi_cell(0, 8, txt=\"Sample Tweets:\\n\", align='L')\n",
    "for i, row in df.head(5).iterrows():\n",
    "    tweet_text = row['text'][:150].encode('latin-1', 'replace').decode('latin-1')\n",
    "    pdf.multi_cell(0, 8, txt=f\"- {tweet_text}... ({row['sentiment_category']})\")\n",
    "\n",
    "pdf.output(\"Tweet_Analysis_Report.pdf\")\n",
    "\n",
    "print(\"ðŸŽ‰ Export complete:\")\n",
    "print(\"- analyzed_tweets.csv\")\n",
    "print(\"- analyzed_tweets.xlsx\")\n",
    "print(\"- sentiment_distribution.png\")\n",
    "print(\"- sentiment_histogram.png\")\n",
    "print(\"- Tweet_Analysis_Report.docx\")\n",
    "print(\"- Tweet_Analysis_Report.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b77e2-5fa4-4c5d-98fa-6314a257aae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
